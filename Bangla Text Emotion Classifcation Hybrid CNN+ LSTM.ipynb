{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eda4d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\python\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,158</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ topic_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,316</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │         \u001b[38;5;34m640,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m24,640\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │           \u001b[38;5;34m1,158\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ topic_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                │           \u001b[38;5;34m2,316\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">766,930</span> (2.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m766,930\u001b[0m (2.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">766,930</span> (2.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m766,930\u001b[0m (2.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 119ms/step - emotion_output_accuracy: 0.3856 - emotion_output_loss: 1.4430 - loss: 3.4392 - topic_output_accuracy: 0.2819 - topic_output_loss: 1.9962 - val_emotion_output_accuracy: 0.5681 - val_emotion_output_loss: 1.0724 - val_loss: 2.5296 - val_topic_output_accuracy: 0.5217 - val_topic_output_loss: 1.4569\n",
      "Epoch 2/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 117ms/step - emotion_output_accuracy: 0.6095 - emotion_output_loss: 1.0103 - loss: 2.3681 - topic_output_accuracy: 0.5624 - topic_output_loss: 1.3578 - val_emotion_output_accuracy: 0.5965 - val_emotion_output_loss: 1.0083 - val_loss: 2.2977 - val_topic_output_accuracy: 0.5779 - val_topic_output_loss: 1.2891\n",
      "Epoch 3/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 119ms/step - emotion_output_accuracy: 0.6709 - emotion_output_loss: 0.8526 - loss: 1.9456 - topic_output_accuracy: 0.6458 - topic_output_loss: 1.0929 - val_emotion_output_accuracy: 0.5940 - val_emotion_output_loss: 1.0135 - val_loss: 2.2698 - val_topic_output_accuracy: 0.5877 - val_topic_output_loss: 1.2560\n",
      "Epoch 4/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 125ms/step - emotion_output_accuracy: 0.7231 - emotion_output_loss: 0.7502 - loss: 1.6794 - topic_output_accuracy: 0.7030 - topic_output_loss: 0.9293 - val_emotion_output_accuracy: 0.5979 - val_emotion_output_loss: 1.0553 - val_loss: 2.3369 - val_topic_output_accuracy: 0.5877 - val_topic_output_loss: 1.2812\n",
      "Epoch 5/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 119ms/step - emotion_output_accuracy: 0.7376 - emotion_output_loss: 0.6911 - loss: 1.5151 - topic_output_accuracy: 0.7352 - topic_output_loss: 0.8240 - val_emotion_output_accuracy: 0.5862 - val_emotion_output_loss: 1.0952 - val_loss: 2.4124 - val_topic_output_accuracy: 0.5887 - val_topic_output_loss: 1.3169\n",
      "Epoch 6/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 132ms/step - emotion_output_accuracy: 0.7612 - emotion_output_loss: 0.6272 - loss: 1.3534 - topic_output_accuracy: 0.7647 - topic_output_loss: 0.7263 - val_emotion_output_accuracy: 0.5711 - val_emotion_output_loss: 1.1566 - val_loss: 2.5403 - val_topic_output_accuracy: 0.5789 - val_topic_output_loss: 1.3833\n",
      "Epoch 7/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 123ms/step - emotion_output_accuracy: 0.7869 - emotion_output_loss: 0.5667 - loss: 1.2281 - topic_output_accuracy: 0.7851 - topic_output_loss: 0.6613 - val_emotion_output_accuracy: 0.5730 - val_emotion_output_loss: 1.2029 - val_loss: 2.6537 - val_topic_output_accuracy: 0.5804 - val_topic_output_loss: 1.4503\n",
      "Epoch 8/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 122ms/step - emotion_output_accuracy: 0.7945 - emotion_output_loss: 0.5423 - loss: 1.1494 - topic_output_accuracy: 0.8010 - topic_output_loss: 0.6070 - val_emotion_output_accuracy: 0.5774 - val_emotion_output_loss: 1.3060 - val_loss: 2.8548 - val_topic_output_accuracy: 0.5730 - val_topic_output_loss: 1.5484\n",
      "Epoch 9/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 119ms/step - emotion_output_accuracy: 0.8104 - emotion_output_loss: 0.4899 - loss: 1.0258 - topic_output_accuracy: 0.8280 - topic_output_loss: 0.5360 - val_emotion_output_accuracy: 0.5711 - val_emotion_output_loss: 1.3250 - val_loss: 2.9215 - val_topic_output_accuracy: 0.5779 - val_topic_output_loss: 1.5960\n",
      "Epoch 10/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 120ms/step - emotion_output_accuracy: 0.8303 - emotion_output_loss: 0.4579 - loss: 0.9733 - topic_output_accuracy: 0.8317 - topic_output_loss: 0.5154 - val_emotion_output_accuracy: 0.5701 - val_emotion_output_loss: 1.4330 - val_loss: 3.1028 - val_topic_output_accuracy: 0.5779 - val_topic_output_loss: 1.6693\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - emotion_output_accuracy: 0.4483 - emotion_output_loss: 2.1366 - loss: 4.0680 - topic_output_accuracy: 0.5046 - topic_output_loss: 1.9313\n",
      "Test Emotion Accuracy: 0.4833\n",
      "Test Topic Accuracy: 0.5255\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step\n",
      "Emotion Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.44      0.44      0.44       472\n",
      "        Fear       0.40      0.04      0.07        51\n",
      "         Joy       0.53      0.64      0.58       774\n",
      "        Love       0.43      0.28      0.34       388\n",
      "     Sadness       0.54      0.56      0.55       470\n",
      "    Surprise       0.18      0.19      0.19       117\n",
      "\n",
      "    accuracy                           0.48      2272\n",
      "   macro avg       0.42      0.36      0.36      2272\n",
      "weighted avg       0.48      0.48      0.47      2272\n",
      "\n",
      "Topic Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.32      0.31      0.31        74\n",
      "    Education       0.47      0.38      0.42       255\n",
      "Entertainment       0.57      0.54      0.56       281\n",
      "      Fashion       0.00      0.00      0.00         8\n",
      "         Food       0.62      0.35      0.45        68\n",
      "         Game       0.60      0.10      0.18        29\n",
      "       Health       0.00      0.00      0.00         5\n",
      "        Music       0.53      0.59      0.56       254\n",
      "     Personal       0.55      0.63      0.59       572\n",
      "     Politics       0.53      0.57      0.55       394\n",
      "       Sports       0.52      0.48      0.50       294\n",
      "       Travel       0.50      0.42      0.46        38\n",
      "\n",
      "     accuracy                           0.53      2272\n",
      "    macro avg       0.43      0.37      0.38      2272\n",
      " weighted avg       0.52      0.53      0.52      2272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Hybrid CNN + LSTM Model for Emotion and Topic Classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'F:\\\\Masters\\\\Thesis\\\\BanglaEmotion\\\\Train.csv'  # Update with your path\n",
    "val_data_path = 'F:\\\\Masters\\\\Thesis\\\\BanglaEmotion\\\\Val.csv'  # Validation data path\n",
    "test_data_path = 'F:\\\\Masters\\\\Thesis\\\\BanglaEmotion\\\\Test.csv'  # Test data path\n",
    "\n",
    "# Load all datasets\n",
    "df = pd.read_csv(data_path)\n",
    "df_val = pd.read_csv(val_data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Combine emotion columns into labels for training, validation, and test data\n",
    "emotion_columns = ['Love', 'Joy', 'Surprise', 'Anger', 'Sadness', 'Fear']\n",
    "df['Emotion_Label'] = df[emotion_columns].idxmax(axis=1)\n",
    "df_val['Emotion_Label'] = df_val[emotion_columns].idxmax(axis=1)\n",
    "df_test['Emotion_Label'] = df_test[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "# Encode labels for emotion and topic\n",
    "emotion_label_encoder = LabelEncoder()\n",
    "df['Emotion_Label'] = emotion_label_encoder.fit_transform(df['Emotion_Label'])\n",
    "df_val['Emotion_Label'] = emotion_label_encoder.transform(df_val['Emotion_Label'])\n",
    "df_test['Emotion_Label'] = emotion_label_encoder.transform(df_test['Emotion_Label'])\n",
    "\n",
    "topic_label_encoder = LabelEncoder()\n",
    "df['Topic'] = topic_label_encoder.fit_transform(df['Topic'])\n",
    "df_val['Topic'] = topic_label_encoder.transform(df_val['Topic'])\n",
    "df_test['Topic'] = topic_label_encoder.transform(df_test['Topic'])\n",
    "\n",
    "# Tokenization and Padding for Text Data\n",
    "max_words = 5000  # Maximum number of words to consider\n",
    "max_len = 100  # Maximum sequence length\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['Data'])\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(df['Data']), maxlen=max_len)\n",
    "X_val = pad_sequences(tokenizer.texts_to_sequences(df_val['Data']), maxlen=max_len)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(df_test['Data']), maxlen=max_len)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_emotion = to_categorical(df['Emotion_Label'])\n",
    "y_val_emotion = to_categorical(df_val['Emotion_Label'])\n",
    "y_test_emotion = to_categorical(df_test['Emotion_Label'])\n",
    "\n",
    "y_train_topic = to_categorical(df['Topic'])\n",
    "y_val_topic = to_categorical(df_val['Topic'])\n",
    "y_test_topic = to_categorical(df_test['Topic'])\n",
    "\n",
    "# Hybrid CNN + LSTM Model\n",
    "embedding_dim = 128\n",
    "num_filters = 64\n",
    "kernel_size = 3\n",
    "lstm_units = 64\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(max_len,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len)(input_layer)\n",
    "\n",
    "# CNN Layer\n",
    "conv_layer = Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(embedding_layer)\n",
    "pool_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = Bidirectional(LSTM(lstm_units, return_sequences=False))(embedding_layer)\n",
    "\n",
    "# Concatenate CNN and LSTM Features\n",
    "concat_layer = Concatenate()([pool_layer, lstm_layer])\n",
    "dropout_layer = Dropout(0.5)(concat_layer)\n",
    "\n",
    "# Dense layers for separate outputs\n",
    "emotion_output = Dense(y_train_emotion.shape[1], activation='softmax', name='emotion_output')(dropout_layer)\n",
    "topic_output = Dense(y_train_topic.shape[1], activation='softmax', name='topic_output')(dropout_layer)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=input_layer, outputs=[emotion_output, topic_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'emotion_output': 'categorical_crossentropy', 'topic_output': 'categorical_crossentropy'},\n",
    "    metrics={'emotion_output': 'accuracy', 'topic_output': 'accuracy'}\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    {'emotion_output': y_train_emotion, 'topic_output': y_train_topic},\n",
    "    validation_data=(X_val, {'emotion_output': y_val_emotion, 'topic_output': y_val_topic}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate on Test Data\n",
    "test_loss, test_emotion_loss, test_topic_loss, test_emotion_acc, test_topic_acc = model.evaluate(\n",
    "    X_test, \n",
    "    {'emotion_output': y_test_emotion, 'topic_output': y_test_topic}\n",
    ")\n",
    "\n",
    "print(f\"Test Emotion Accuracy: {test_emotion_acc:.4f}\")\n",
    "print(f\"Test Topic Accuracy: {test_topic_acc:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "emotion_pred = np.argmax(model.predict(X_test)[0], axis=1)\n",
    "topic_pred = np.argmax(model.predict(X_test)[1], axis=1)\n",
    "\n",
    "# Classification Reports\n",
    "print(\"Emotion Classification Report on Test Data:\")\n",
    "print(classification_report(np.argmax(y_test_emotion, axis=1), emotion_pred, target_names=emotion_label_encoder.classes_))\n",
    "\n",
    "print(\"Topic Classification Report on Test Data:\")\n",
    "print(classification_report(np.argmax(y_test_topic, axis=1), topic_pred, target_names=topic_label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1956c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
